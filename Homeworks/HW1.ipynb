{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HW1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2hGlZ4vKpQfC"
      },
      "source": [
        "1)How would you define Machine Learning?\n",
        "\n",
        "\n",
        "-Machine learning is probably the most coomon form of AI in action today\n",
        "-Machine learning is an application  that provides systems the ability to automatically learn and improve from experience without being explicitly programmed.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "2) What are the differences between Supervised and Unsupervised\n",
        " Learning? Specify example 3 algorithms for each of these.\n",
        "Supervised learning:\n",
        "-In Supervised learning input data is labelled.\n",
        "-Uses training dataset\n",
        "-Used for prediction\n",
        "-Known number of classes\n",
        "-Divided into classification and Regression\n",
        " Example: Sales performance prediction\n",
        " Algorithms :\n",
        " -Linear Regression\n",
        " -Random Forest\n",
        " -support vector machine\n",
        "\n",
        "\n",
        "\n",
        "Unsupervised learning:\n",
        "-In Unsupervised learning input data is unlabelled.\n",
        "-uses just input dataset\n",
        "-used for analysis\n",
        "-Unknown number of classes\n",
        "-Divided into Clustering and Association.\n",
        " Example:fraud detetction\n",
        " Algorithms:\n",
        " -Principle Component Analysis.\n",
        " -Apriori algorithm.\n",
        " -K-means clustering\n",
        "\n",
        "\n",
        "\n",
        "3) What are the test and validation set, and why would you want to use them?\n",
        "\n",
        "-Test dataset:\n",
        "Test dataset is predominately used to describe the evaluation of a final tuned model when comparing it to other final models.\n",
        "-Validation dataset:\n",
        "Validation set actually can be regarded as a part of training set, because it is used to build your model, neural networks.\n",
        "Validation set is predominately used to describe the evaluation of models when tuning hyperparameters and data preparation.\n",
        "Why to use:\n",
        "Validation set is used for tuning the parameters of a model.\n",
        "Test set is used for performance evaluation.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "4) What are the main preprocessing steps? Explain them in detail. Why we need to prepare our data?\n",
        "\n",
        "-Getting the dataset\n",
        "-Importing libraries\n",
        "-Importing datasets\n",
        "-Finding Missing Data\n",
        "- Encoding Categorical Data\n",
        "-Splitting dataset into training and test set\n",
        "-Feature scaling\n",
        "\n",
        "Getting the dataset:\n",
        "To create a machine learning model, the first thing we required is a dataset as a machine learning model completely works on data. The collected data for a particular problem in a proper format is known as the dataset.\n",
        "Dataset may be of different formats  like CSV,for different purposes \n",
        "Importing libraries:\n",
        "In order to perform data preprocessing using Python, we need to import some predefined Python libraries. \n",
        "These libraries are used to perform some specific jobs. \n",
        "There are three specific libraries that we will use for data preprocessing, which are:\n",
        "Numpy\n",
        "matplotlib\n",
        "pandas\n",
        "Importing datasets\n",
        "Now we need to import the datasets which we have collected for our machine learning project.\n",
        "Handling missing values:\n",
        "The next step of data preprocessing is to handle missing data in the datasets. If our dataset contains some missing data, then it may create a huge problem for our machine learning model. Hence it is necessary to handle missing values present in the dataset.\n",
        "Ways to handle missing data:\n",
        "By deleting the particular row\n",
        "By calculating the mean\n",
        "we can also use Scikit-learn library in our code to handle missing values, which contains various libraries for building machine learning models. Here we will use Imputer class of sklearn.preprocessing library.\n",
        "Encoding Categorical Data\n",
        "Categorical data is data which has some categories such as, in our dataset; there are two categorical variable, Country, and Purchased.\n",
        "Since machine learning model completely works on mathematics and numbers, but if our dataset would have a categorical variable, then it may create trouble while building the model. So it is necessary to encode these categorical variables into numbers.\n",
        "\n",
        "\n",
        "\n",
        "Splitting dataset into training and test set:\n",
        "In machine learning data preprocessing, we divide our dataset into a training set and test set. \n",
        "This is one of the crucial steps of data preprocessing as by doing this, we can enhance the performance of our machine learning model.\n",
        "Training Set:A subset of dataset to train the machine learning model, and we already know the output.\n",
        "Test set:A subset of dataset to test the machine learning model, and by using the test set, model predicts the output.\n",
        "Feature scaling:\n",
        "Feature scaling is the final step of data preprocessing in machine learning. It is a technique to standardize the independent variables of the dataset in a specific range. \n",
        "\n",
        "In feature scaling, we put our variables in the same range and in the same scale so that no any variable dominate the other variable.\n",
        "\n",
        "Why to use preprocessing:\n",
        "A real-world data generally contains noises, missing values, and maybe in an unusable format which cannot be directly used for machine learning models. \n",
        "Data preprocessing is required tasks for cleaning the data and making it suitable for a machine learning model which also increases the accuracy and efficiency of a machine learning model.\n",
        "\n",
        "5) How you can explore countionus and discrete variables\n",
        "Discrete variable: \n",
        "Discrete data have finite values it can be numerical and can also be in categorical form.These  attributes has finite or countably infinite set of values.\n",
        "Eg: number of heads when flipping three coins\n",
        "Continuonus variable:\n",
        "Continuous data have infinite no of states .Continuous data is of float type. There can be many values between 2 and 3.\n",
        "Eg: time it takes to get to school\n",
        "\n",
        "\n",
        "\n",
        "6)6) Analyse the plot given below. (What is the plot and variable type, check the distribution and make comment about how you can preproccess it.)\n",
        "\n",
        "This is a graph showing flower width on the horizontal axis and their proportions on the vertical axis. This graph consist of a curve (distinct line) so the type of data variable is continuous. Rises and drops are observed according to the rate of change of the distribution.\n",
        "\n",
        "Process:\n",
        "\n",
        "Gathering Data -> Sorting into Balanced and Imbalanced Data -> Balancing the Imbalanced Data -> Fitting Missing Values with the Mean or Median -> Cleaning Noise Data -> Standardization and Normalization -> Feature Extraction (PCA) -> Dataset Split -> Ready\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8aZrufB4tKmu"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}